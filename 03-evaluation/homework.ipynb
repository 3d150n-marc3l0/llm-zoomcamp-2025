{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e90bc966-f95e-4b8e-94fc-fce35d491781",
   "metadata": {},
   "source": [
    "## Homework: Search Evaluation\n",
    "\n",
    "In this homework, we will evaluate the results of vector\n",
    "search.\n",
    "\n",
    "> It's possible that your answers won't match exactly. If it's the case, select the closest one.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab3cd43-509f-4896-8b91-3c142b7931bd",
   "metadata": {},
   "source": [
    "## Required libraries\n",
    "\n",
    "We will use minsearch and Qdrant. Make sure you have the most up-to-date versions:\n",
    "\n",
    "```bash\n",
    "pip install -U minsearch qdrant_client\n",
    "``` \n",
    "\n",
    "minsearch should be at least 0.0.4.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d6176a8-3560-44d3-9fbf-f76adedd7da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.0.4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import minsearch\n",
    "minsearch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f51941-8a0f-46bf-a62f-6e287d442654",
   "metadata": {},
   "source": [
    "## Evaluation data\n",
    "\n",
    "For this homework, we will use the same dataset we generated\n",
    "in the videos.\n",
    "\n",
    "Let's get them:\n",
    "\n",
    "```python\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "url_prefix = 'https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/03-evaluation/'\n",
    "docs_url = url_prefix + 'search_evaluation/documents-with-ids.json'\n",
    "documents = requests.get(docs_url).json()\n",
    "\n",
    "ground_truth_url = url_prefix + 'search_evaluation/ground-truth-data.csv'\n",
    "df_ground_truth = pd.read_csv(ground_truth_url)\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')\n",
    "```\n",
    "\n",
    "Here, `documents` contains the documents from the FAQ database\n",
    "with unique IDs, and `ground_truth` contains generated\n",
    "question-answer pairs. \n",
    "\n",
    "Also, we will need the code for evaluating retrieval:\n",
    "\n",
    "```python\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)\n",
    "\n",
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['document']\n",
    "        results = search_function(q)\n",
    "        relevance = [d['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96413cdb-5627-494e-a161-902109f0d89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "url_prefix = 'https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/03-evaluation/'\n",
    "docs_url = url_prefix + 'search_evaluation/documents-with-ids.json'\n",
    "documents = requests.get(docs_url).json()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39f5cebd-81f8-4ea9-b301-e295a3892faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - When will the course start?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': 'c02e79ef'},\n",
       " {'text': 'GitHub - DataTalksClub data-engineering-zoomcamp#prerequisites',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - What are the prerequisites for this course?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': '1f6520ca'},\n",
       " {'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I still join the course after the start date?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': '7842b56a'},\n",
       " {'text': \"You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': '0bbf41ec'},\n",
       " {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - What can I do before the course starts?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': '63394d91'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show sample\n",
    "documents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d04a530-7b1b-47d1-96f4-8e9d30475207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read ground-thruh\n",
    "ground_truth_url = url_prefix + 'search_evaluation/ground-truth-data.csv'\n",
    "df_ground_truth = pd.read_csv(ground_truth_url)\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a02b22bb-d66f-4f20-b8df-4cf3d610d595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'When does the course begin?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'document': 'c02e79ef'},\n",
       " {'question': 'How can I get the course schedule?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'document': 'c02e79ef'},\n",
       " {'question': 'What is the link for course registration?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'document': 'c02e79ef'},\n",
       " {'question': 'How can I receive course announcements?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'document': 'c02e79ef'},\n",
       " {'question': 'Where do I join the Slack channel?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'document': 'c02e79ef'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show sample ground-thruh\n",
    "ground_truth[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e95f9285-673b-4136-8348-eddbf6d85d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'When does the course begin?', 'course': 'data-engineering-zoomcamp', 'document': 'c02e79ef'}\n",
      "{'question': 'How can I get the course schedule?', 'course': 'data-engineering-zoomcamp', 'document': 'c02e79ef'}\n",
      "{'question': 'What is the link for course registration?', 'course': 'data-engineering-zoomcamp', 'document': 'c02e79ef'}\n",
      "{'question': 'How can I receive course announcements?', 'course': 'data-engineering-zoomcamp', 'document': 'c02e79ef'}\n",
      "{'question': 'Where do I join the Slack channel?', 'course': 'data-engineering-zoomcamp', 'document': 'c02e79ef'}\n"
     ]
    }
   ],
   "source": [
    "for doc in ground_truth:\n",
    "    if 'c02e79ef' == doc['document']:\n",
    "        print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cb7a3c2-efca-4cde-a362-8a3fc9b6a9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)\n",
    "\n",
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['document']\n",
    "        results = search_function(q)\n",
    "        relevance = [d['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b684543e-878d-4b05-b8f3-2726f22fe42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94a71693-6581-4bfb-881e-59ba0b651231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.minsearch.Index at 0x7cfee6bf1fd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create index\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011a4a8c-7cea-46ce-bbce-228dfbf38dbd",
   "metadata": {},
   "source": [
    "## Q1. Minsearch text\n",
    "\n",
    "Now let's evaluate our usual minsearch approach, but tweak\n",
    "the parameters. Let's use the following boosting \n",
    "params:\n",
    "\n",
    "```python\n",
    "boost = {'question': 1.5, 'section': 0.1}\n",
    "```\n",
    "\n",
    "What's the hitrate for this approach?\n",
    "\n",
    "* 0.64\n",
    "* 0.74\n",
    "* 0.84\n",
    "* 0.94\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4624c9f-eeb2-4dec-a7e2-244687c2b7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsearch_search(query:str, course:str='data-engineering-zoomcamp'):\n",
    "    boost = {'question': 1.5, 'section': 0.1}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': course},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "697c7d41-faaf-453e-84fc-a1c670e6be21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28e210e703c3416e9686791456ca8860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4627 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hit_rate': 0.848714069591528, 'mrr': 0.7288235717887772}\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "q1_results = evaluate(ground_truth, lambda q: minsearch_search(q['question'], q['course']))\n",
    "print(q1_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b358576c-951e-4bc9-9f7c-1285ef81c6b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.848714069591528"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_results['hit_rate']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f27e0c0-db53-4290-ada0-7bbac36c7fb3",
   "metadata": {},
   "source": [
    "What's the hitrate for this approach?\n",
    "\n",
    "* 0.64\n",
    "* 0.74\n",
    "* **0.84** <span style=\"font-size: 1.2em;\">⬅️</span>\n",
    "* 0.94"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26b286e-e913-4d62-9890-53fe31aabe07",
   "metadata": {},
   "source": [
    "## Embeddings \n",
    "\n",
    "The latest version of minsearch also supports vector search. \n",
    "We will use it:\n",
    "\n",
    "```python\n",
    "from minsearch import VectorSearch\n",
    "```\n",
    "\n",
    "We will also use TF-IDF and Singular Value Decomposition to \n",
    "create embeddings from texts. You can refer to our\n",
    "[\"Create Your Own Search Engine\" workshop](https://github.com/alexeygrigorev/build-your-own-search-engine)\n",
    "if you want to know more about it.\n",
    "\n",
    "```python\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "```\n",
    "\n",
    "Let's create embeddings for the \"question\" field:\n",
    "\n",
    "```python\n",
    "texts = []\n",
    "\n",
    "for doc in documents:\n",
    "    t = doc['question']\n",
    "    texts.append(t)\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(min_df=3),\n",
    "    TruncatedSVD(n_components=128, random_state=1)\n",
    ")\n",
    "X = pipeline.fit_transform(texts)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab67be11-7f4b-4692-a342-cd5d724eb316",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minsearch import VectorSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4584e6bc-1984-4d5a-af35-aa9002792bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c027b94-07ca-4acd-aa51-77665799967b",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "\n",
    "for doc in documents:\n",
    "    t = doc['question']\n",
    "    texts.append(t)\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(min_df=3),\n",
    "    TruncatedSVD(n_components=128, random_state=1)\n",
    ")\n",
    "X = pipeline.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "96c728bc-907f-4cee-9417-1e7a02d8d6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline.transform([texts[0]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0f897046-0cfc-4139-a9a0-43cff581bcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f164f537-3629-4886-8f46-fe8d09becb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60e100b-9a7b-42d0-b82b-16a87ece5b79",
   "metadata": {},
   "source": [
    "## Q2. Vector search for question\n",
    "\n",
    "Now let's index these embeddings with minsearch:\n",
    "\n",
    "```python\n",
    "vindex = VectorSearch(keyword_fields={'course'})\n",
    "vindex.fit(X, documents)\n",
    "```\n",
    "\n",
    "Evaluate this seach method. What's MRR for it?\n",
    "\n",
    "- 0.25\n",
    "- 0.35\n",
    "- 0.45\n",
    "- 0.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8e172ad4-e47c-4733-9c6a-f8741f6f1d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.vector.VectorSearch at 0x7cfee5704380>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create index\n",
    "vindex = VectorSearch(keyword_fields={'course'})\n",
    "vindex.fit(X, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d683eca0-3cff-43ef-8bdd-6272879fea91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsearch_vector_search(vector, course):\n",
    "    # Search\n",
    "    return vindex.search(\n",
    "        vector,\n",
    "        filter_dict={'course': course},\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "def question_text_vector(q):\n",
    "    question = q['question']\n",
    "    course = q['course']\n",
    "\n",
    "    # Create embedding\n",
    "    v_q = pipeline.transform([question])\n",
    "\n",
    "    return minsearch_vector_search(v_q, course) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "279fb0cf-709b-4d2b-9836-f488b5154c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed7b662a150a4ee19514ee091333b354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4627 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hit_rate': 0.48173762697212014, 'mrr': 0.3572833369353793}\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "q2_results = evaluate(ground_truth, question_text_vector)\n",
    "print(q2_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "77ec8424-0f70-4353-a34a-32cc841a42e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.48173762697212014, 'mrr': 0.3572833369353793}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b31700ae-e5c8-4f8f-b908-676787ca509d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3572833369353793"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_results['mrr']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e6cd22-cf3c-4059-926f-a2b92faae443",
   "metadata": {},
   "source": [
    "Evaluate this seach method. What's MRR for it?\n",
    "\n",
    "- 0.25\n",
    "- **0.35** <span style=\"font-size: 1.2em;\">⬅️</span>\n",
    "- 0.45\n",
    "- 0.55"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b398531e-d3c6-4c7f-b9c1-8de2eaccde7c",
   "metadata": {},
   "source": [
    "## Q3. Vector search for question and answer\n",
    "\n",
    "We only used question in Q2. We can use both question and answer:\n",
    "\n",
    "```python\n",
    "texts = []\n",
    "\n",
    "for doc in documents:\n",
    "    t = doc['question'] + ' ' + doc['text']\n",
    "    texts.append(t)\n",
    "```\n",
    "\n",
    "Using the same pipeline (`min_df=3 for TF-IDF vectorizer and `n_components=128` for SVD), evaluate the performance of this\n",
    "approach\n",
    "\n",
    "What's the hitrate?\n",
    "\n",
    "- 0.62\n",
    "- 0.72\n",
    "- 0.82\n",
    "- 0.92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9d8b87cf-ecb2-437b-a301-9c086ebd525c",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "\n",
    "for doc in documents:\n",
    "    t = doc['question'] + ' ' + doc['text']\n",
    "    texts.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5b50bd3b-eee6-4e4c-887a-7e5ee9988899",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(min_df=3),\n",
    "    TruncatedSVD(n_components=128, random_state=1)\n",
    ")\n",
    "X = pipeline.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "67b11bba-914b-422f-8165-1b5f734b78c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.vector.VectorSearch at 0x7cfee56fc110>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vindex = VectorSearch(keyword_fields={'course'})\n",
    "vindex.fit(X, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aab5eae8-8889-47de-a4f8-3d77aa2cea57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06c9f38bf050442099176b51c6f3e71c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4627 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hit_rate': 0.8210503566025502, 'mrr': 0.6717347453353508}\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "q3_results = evaluate(ground_truth, question_text_vector)\n",
    "print(q3_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "02880ac1-36bc-453a-8f66-4ce06972aafe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8210503566025502"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3_results['hit_rate']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d305bae-2ad0-49c3-981c-eda4410a3a29",
   "metadata": {},
   "source": [
    "What's the hitrate?\n",
    "\n",
    "- 0.62\n",
    "- 0.72\n",
    "- **0.82** <span style=\"font-size: 1.2em;\">⬅️</span>\n",
    "- 0.92"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b66205a-d9fa-42d3-8e92-12b943b55415",
   "metadata": {},
   "source": [
    "## Q4. Qdrant\n",
    "\n",
    "Now let's evaluate the following settings in Qdrant:\n",
    "\n",
    "- `text = doc['question'] + ' ' + doc['text']`\n",
    "- `model_handle = \"jinaai/jina-embeddings-v2-small-en\"`\n",
    "- `limit = 5`\n",
    "\n",
    "What's the MRR?\n",
    "\n",
    "- 0.65\n",
    "- 0.75\n",
    "- 0.85\n",
    "- 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b278e4d0-782d-478a-a546-9459ee2d0bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastembed import TextEmbedding\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "from qdrant_client.models import (\n",
    "    PointStruct,\n",
    "    VectorParams,\n",
    "    Distance,\n",
    "    Filter,\n",
    "    FieldCondition,\n",
    "    Match\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e15886-39fe-4a59-8c9d-8a256cbc1423",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_handle = \"jinaai/jina-embeddings-v2-small-en\"\n",
    "embedding_model = TextEmbedding(model_name=model_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15e55ec-88fc-4787-b99c-e5184cebbe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [doc[\"question\"] + \" \" + doc[\"text\"] for doc in documents]\n",
    "embeddings = list(embedding_model.embed(texts))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e190360",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = QdrantClient(\":memory:\")\n",
    "\n",
    "client.recreate_collection(\n",
    "    collection_name=\"zoomcamp-quadrant\",\n",
    "    vectors_config=VectorParams(size=512, distance=Distance.COSINE)\n",
    ")\n",
    "\n",
    "points = [\n",
    "    PointStruct(id=i, vector=embeddings[i], payload=documents[i])\n",
    "    for i in range(len(documents))\n",
    "]\n",
    "\n",
    "client.upsert(collection_name=\"zoomcamp-quadrant\", points=points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad8efaa-322f-4925-a4c9-19c3f96ef36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qdrant_vector_search(q):\n",
    "    question = q[\"question\"]\n",
    "    query_vec = next(embedding_model.embed([question]))\n",
    "\n",
    "    hits = client.search(\n",
    "        collection_name=\"zoomcamp-quadrant\",\n",
    "        query_vector=query_vec,\n",
    "        limit=5\n",
    "    )\n",
    "\n",
    "    return [{\"id\": hit.payload[\"id\"]} for hit in hits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22b70e8-b069-4f5e-8662-8e348a997d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "q4_results = evaluate(ground_truth, qdrant_vector_search)\n",
    "print(q4_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83d9be2-f306-4dbd-82c2-4a20e53da81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "q4_results[\"mrr\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2245a3ac-02cf-43d0-a066-15eecf2f668b",
   "metadata": {},
   "source": [
    "What's the MRR?\n",
    "\n",
    "- 0.65\n",
    "- **0.75** <span style=\"font-size: 1.2em;\">⬅️</span>\n",
    "- 0.85\n",
    "- 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7895d52a-c012-4f2f-94a3-cecdc8dfb64e",
   "metadata": {},
   "source": [
    "## Q5. Cosine simiarity\n",
    "\n",
    "In the second part of the module, we looked at evaluating\n",
    "the entire RAG approach. In particular, we looked at \n",
    "comparing the answer generated by our system with the actual\n",
    "answer from the FAQ.\n",
    "\n",
    "One of the ways of doing it is using the cosine similarity. \n",
    "Let's see how to calculate it.\n",
    "\n",
    "Cosine similarity is a dot product between two normalized vectors.\n",
    "In geometrical sense, it's the cosine of the angle between\n",
    "the vectors. Look up \"cosine similarity geometry\" if you want to\n",
    "learn more about it.\n",
    "\n",
    "For us, it means that we need two things:\n",
    "\n",
    "- First, we normalize each of the vectors\n",
    "- Then, compute the dot product\n",
    "\n",
    "So, we get this:\n",
    "\n",
    "```python\n",
    "def cosine(u, v):\n",
    "    u = normalize(u)\n",
    "    v = normalize(v)\n",
    "    return u.dot(v)\n",
    "```\n",
    "\n",
    "For normalization, we first compute the vector norm (its length),\n",
    "and then divide the vector by it:\n",
    "\n",
    "```python\n",
    "def normalize(u):\n",
    "    norm = np.sqrt(u.dot(u))\n",
    "    return u / norm\n",
    "```\n",
    "\n",
    "(where `np` is `import numpy as np`)\n",
    "\n",
    "Or we can simplify it:\n",
    "\n",
    "```python\n",
    "def cosine(u, v):\n",
    "    u_norm = np.sqrt(u.dot(u))\n",
    "    v_norm = np.sqrt(v.dot(v))\n",
    "    return u.dot(v) / (u_norm * v_norm)\n",
    "```\n",
    "\n",
    "Now let's use this function to compute the\n",
    "A->Q->A cosine similarity.\n",
    "\n",
    "We will use the results from [our gpt-4o-mini evaluations](https://github.com/DataTalksClub/llm-zoomcamp/blob/main/03-evaluation/rag_evaluation/data/results-gpt4o-mini.csv):\n",
    "\n",
    "\n",
    "```python\n",
    "results_url = url_prefix + 'rag_evaluation/data/results-gpt4o-mini.csv'\n",
    "df_results = pd.read_csv(results_url)\n",
    "```\n",
    "\n",
    "\n",
    "When creating embeddings, we will use a simple way -\n",
    "the same we used in the [Embeddings](#embeddings) section:\n",
    "\n",
    "```python\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(min_df=3),\n",
    "    TruncatedSVD(n_components=128, random_state=1)\n",
    ")\n",
    "```\n",
    "\n",
    "Let's fit the vectorizer on all the text data we have:\n",
    "\n",
    "```python\n",
    "pipeline.fit(df_results.answer_llm + ' ' + df_results.answer_orig + ' ' + df_results.question)\n",
    "```\n",
    "\n",
    "Now use the `transform` methon of the pipeline to create the embeddings and calculate the cosine similarity between each\n",
    "pair.\n",
    "\n",
    "What's the average cosine?\n",
    "\n",
    "- 0.64\n",
    "- 0.74\n",
    "- 0.84\n",
    "- 0.94\n",
    "\n",
    "This is how you do it:\n",
    "\n",
    "- For each answer pair, compute\n",
    "    - `v_llm` for the answer from the LLM \n",
    "    - `v_orig` for the original answer\n",
    "    - then compute the cosine between them\n",
    "- At the end, take the average\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044be5fd-9bb3-47d5-ad84-e5e799da410e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad1576c8-5f9e-4657-8f39-e7bce249e2ee",
   "metadata": {},
   "source": [
    "## Q6. Rouge\n",
    "\n",
    "And alternative way to see how two texts are similar is ROUGE. \n",
    "\n",
    "This is a set of metrics that compares two answers based on the overlap of n-grams, word sequences, and word pairs.\n",
    "\n",
    "It can give a more nuanced view of text similarity than just cosine similarity alone.\n",
    "\n",
    "We don't need to implement it ourselves, there's a python package for it:\n",
    "\n",
    "```bash\n",
    "pip install rouge\n",
    "```\n",
    "\n",
    "(The latest version at the moment of writing is `1.0.1`)\n",
    "\n",
    "Let's compute the ROUGE score between the answers at the index 10 of our dataframe (`doc_id=5170565b`)\n",
    "\n",
    "```\n",
    "from rouge import Rouge\n",
    "rouge_scorer = Rouge()\n",
    "\n",
    "r = df_results.iloc[10]\n",
    "scores = rouge_scorer.get_scores(r.answer_llm, r.answer_orig)[0]\n",
    "scores\n",
    "```\n",
    "\n",
    "There are three scores: `rouge-1`, `rouge-2` and `rouge-l`, and precision, recall and F1 score for each.\n",
    "\n",
    "* `rouge-1` - the overlap of unigrams,\n",
    "* `rouge-2` - bigrams,\n",
    "* `rouge-l` - the longest common subsequence\n",
    "\n",
    "For the 10th document, Rouge-1 F1 score is 0.45\n",
    "\n",
    "Let's compute it for the pairs in the entire dataframe.\n",
    "What's the average Rouge-1 F1?\n",
    "\n",
    "- 0.25\n",
    "- 0.35\n",
    "- 0.45\n",
    "- 0.55\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322aede2-16b6-426d-9dd1-f1df4cfdcd4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c86645-f345-43ac-9292-013c001b710c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a9b108a-d17c-4c4a-bbfb-928868208ca1",
   "metadata": {},
   "source": [
    "## Submit the results\n",
    "\n",
    "* Submit your results here: https://courses.datatalks.club/llm-zoomcamp-2025/homework/hw3\n",
    "* It's possible that your answers won't match exactly. If it's the case, select the closest one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4be488b-d718-4abd-98eb-cfbf41aaa952",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
